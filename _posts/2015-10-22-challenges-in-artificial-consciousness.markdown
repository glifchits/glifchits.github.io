---
published: false
title: Challenges in artificial consciousness
layout: post
---
One of the beliefs I hold quite strongly about artificial intelligence is that **consciousness is computable**.

Neural networks are probably the field of research that is most directly aimed at proving that claim. I think the easiest way of understanding the concept is to imagine that neurons in our brains are mechanical, and perhaps we can model how they work.
And the best part is that the neural network model is working quite well so far. Researchers are able to use neural network architectures to identify what's going on in complicated images and videos.

Neural networks are trained with lots of data. If we wanted our neural network to identify pictures that have a dog in them, we'll train it with pictures of dogs so that it knows what dogs look like. But what if we want to give rise to consciousness? Let's consider some of the hurdles we face before we're anywhere close to artificial consciousness.

# Human perception is a firehose of unstructured data

The most effective neural networks are trained on homogenous data, for a very specific purpose (e.g. images and their descriptions to train image classification, or voice recordings and grammars for training to transcribe speech to text). In comparison, we are continuously bombarded with all sorts of sensory inputs. Think about sitting in a caf√©; the sounds of people talking, espresso machines whistling, soft jazz in the background, and street sounds outside; cars honking, construction rattling. Now think about the diversity of sights, smells and tastes. Even 10 million pictures of trees is no match for 2 minutes of human experience. The "learning objectives" of every day life are hard to define.

# Instinct is an abundant, precious set of training data

After millions of years of human evolution, we've learned from the experiences of our fittest ancestors. Innate abilities are the origin of some of our most powerful reflexes, and provide us with lots of important heuristics for decision making. They may have even provide faculties to help us [understand different languages](http://qz.com/529865/study-a-fascinating-aspect-of-language-looks-to-be-biologically-hardwired-in-our-brains/).

Its hard to fathom the kind of data we'd need to begin teaching computers these critical innate behaviours. The alternative to constructing the raw "instincts" dataset would be to enumerate and define all of the knowledge and decision heuristics that humans use. Even a representative subset of these would be very hard to build, requiring contributions from neuroscience, psychology, anthropology, behavioural science, and countless other fields.

# Encoding unstructured data is hard

Some of the earliest artificial intelligence research revolves around the idea of symbolic manipulation. If concepts were represented as "symbols", then surely computers would be able to derive conclusions by performing legal (logical) manipulations on those symbols. But what is the mapping between real-world objects and symbols? The idea of **abstraction** is noteworthy here. How can we teach computers to construct abstractions from data, and how can the computer know if they are valid? Moreover, how does a computer navigate between different levels of abstraction?

# The role of unconsciousness

A great deal of brain activity occurs in the background, out of the realm of our consciousness. The prospect of explicitly defining an procedure which models the process of unconscious thinking is almost a contradiction -- it would require a conscious understanding of unconsciousness.

With all this said, I am still optimistic about the future of artificial consciousness. After all, the human body is a mechanism, and so is a computer. And if the brain is a mechanism, and the brain gives rise to consciousness, then it should follow that a mechanism can give rise to consciousness. I don't see what is inherently different about the human body that cannot be modelled by a computer. Maybe the task of creating AI actually doesn't even involve tackling each of these issues individually as much as it involves creating a sufficiently complex process that mimics the biological processes of the brain.

Food for thought.